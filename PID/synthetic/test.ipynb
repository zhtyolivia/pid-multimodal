{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1loDGSKIBdbU"
      },
      "outputs": [],
      "source": [
        "import cvxpy as cp\n",
        "import numpy as np\n",
        "from scipy.special import rel_entr\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Y2kU6J8vzGRi"
      },
      "outputs": [],
      "source": [
        "def solve_Q_new(P: np.ndarray):\n",
        "  '''\n",
        "  Compute optimal Q given 3d array P \n",
        "  with dimensions coressponding to x1, x2, and y respectively\n",
        "  '''\n",
        "  Py = P.sum(axis=0).sum(axis=0)\n",
        "  Px1 = P.sum(axis=1).sum(axis=1)\n",
        "  Px2 = P.sum(axis=0).sum(axis=1)\n",
        "  Px2y = P.sum(axis=0)\n",
        "  Px1y = P.sum(axis=1)\n",
        "  Px1y_given_x2 = P/P.sum(axis=(0,2),keepdims=True)\n",
        " \n",
        "  Q = [cp.Variable((P.shape[0], P.shape[1]), nonneg=True) for i in range(P.shape[2])]\n",
        "  Q_x1x2 = [cp.Variable((P.shape[0], P.shape[1]), nonneg=True) for i in range(P.shape[2])]\n",
        "\n",
        "  # Constraints that conditional distributions sum to 1\n",
        "  sum_to_one_Q = cp.sum([cp.sum(q) for q in Q]) == 1\n",
        "\n",
        "  # Brute force constraints # \n",
        "  # [A]: p(x1, y) == q(x1, y) \n",
        "  # [B]: p(x2, y) == q(x2, y)\n",
        "\n",
        "  # Adding [A] constraints\n",
        "  A_cstrs = []\n",
        "  for x1 in range(P.shape[0]):\n",
        "      for y in range(P.shape[2]):\n",
        "        vars = []\n",
        "        for x2 in range(P.shape[1]):\n",
        "          vars.append(Q[y][x1, x2])\n",
        "        A_cstrs.append(cp.sum(vars) == Px1y[x1,y])\n",
        "  \n",
        "  # Adding [B] constraints\n",
        "  B_cstrs = []\n",
        "  for x2 in range(P.shape[1]):\n",
        "      for y in range(P.shape[2]):\n",
        "        vars = []\n",
        "        for x1 in range(P.shape[0]):\n",
        "          vars.append(Q[y][x1, x2])\n",
        "        B_cstrs.append(cp.sum(vars) == Px2y[x2,y])\n",
        "\n",
        "  # KL divergence\n",
        "  Q_pdt_dist_cstrs = [cp.sum(Q) / P.shape[2] == Q_x1x2[i] for i in range(P.shape[2])]\n",
        "\n",
        "\n",
        "  # objective\n",
        "  obj = cp.sum([cp.sum(cp.rel_entr(Q[i], Q_x1x2[i])) for i in range(P.shape[2])])\n",
        "  # print(obj.shape)\n",
        "  all_constrs = [sum_to_one_Q] + A_cstrs + B_cstrs + Q_pdt_dist_cstrs\n",
        "  prob = cp.Problem(cp.Minimize(obj), all_constrs)\n",
        "  prob.solve(verbose=False, max_iters=50000)\n",
        "\n",
        "  # print(prob.status)\n",
        "  # print(prob.value)\n",
        "  # for j in range(P.shape[1]):\n",
        "  #  print(Q[j].value)\n",
        "\n",
        "  return np.stack([q.value for q in Q],axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E5K-tL7jd6kB"
      },
      "outputs": [],
      "source": [
        "def gen_binary_data(num_data):\n",
        "  # 00  0\n",
        "  # 01  0\n",
        "  # 10  0\n",
        "  # 11  1\n",
        "\n",
        "  x1 = np.random.randint(0, 2, (num_data, 1))\n",
        "  x2 = np.random.randint(0, 2, (num_data, 1))\n",
        "  data = {\n",
        "      'and': (x1, x2, 1 * np.logical_and(x1, x2)),\n",
        "      'or': (x1, x2, 1 * np.logical_or(x1, x2)),\n",
        "      'xor': (x1, x2, 1 * np.logical_xor(x1, x2)),\n",
        "      'unique1': (x1, x2, x1),\n",
        "      'redundant': (x1, x1, x1),\n",
        "      'redundant_and_unique1': (np.concatenate([x1, x2], axis=1), x2, 1 * np.logical_and(x1, x2)),\n",
        "      'redundant_or_unique1': (np.concatenate([x1, x2], axis=1), x2, 1 * np.logical_or(x1, x2)),\n",
        "      'redundant_xor_unique1': (np.concatenate([x1, x2], axis=1), x2, 1 * np.logical_xor(x1, x2)),\n",
        "  }\n",
        "  return data\n",
        "\n",
        "def convert_data_to_distribution(x1: np.ndarray, x2: np.ndarray, y: np.ndarray):\n",
        "  assert x1.size == x2.size\n",
        "  assert x1.size == y.size\n",
        "\n",
        "  numel = x1.size\n",
        "  \n",
        "  x1_discrete, x1_raw_to_discrete = extract_categorical_from_data(x1.squeeze())\n",
        "  x2_discrete, x2_raw_to_discrete = extract_categorical_from_data(x2.squeeze())\n",
        "  y_discrete, y_raw_to_discrete = extract_categorical_from_data(y.squeeze())\n",
        "\n",
        "  joint_distribution = np.zeros((len(x1_raw_to_discrete), len(x2_raw_to_discrete), len(y_raw_to_discrete)))\n",
        "  for i in range(numel):\n",
        "    joint_distribution[x1_discrete[i], x2_discrete[i], y_discrete[i]] += 1\n",
        "  joint_distribution /= np.sum(joint_distribution)\n",
        "\n",
        "  return joint_distribution, (x1_raw_to_discrete, x2_raw_to_discrete, y_raw_to_discrete)\n",
        "\n",
        "def extract_categorical_from_data(x):\n",
        "  supp = set(x)\n",
        "  raw_to_discrete = dict()\n",
        "  for i in supp:\n",
        "    raw_to_discrete[i] = len(raw_to_discrete)\n",
        "  discrete_data = [raw_to_discrete[x_] for x_ in x]\n",
        "\n",
        "  return discrete_data, raw_to_discrete \n",
        "\n",
        "def MI(P: np.ndarray):\n",
        "  ''' P has 2 dimensions '''\n",
        "  margin_1 = P.sum(axis=1)\n",
        "  margin_2 = P.sum(axis=0)\n",
        "  outer = np.outer(margin_1, margin_2)\n",
        "\n",
        "  return np.sum(rel_entr(P, outer))\n",
        "  # return np.sum(P * np.log(P/outer))\n",
        "\n",
        "def CoI(P:np.ndarray):\n",
        "  ''' P has 3 dimensions, in order X1, X2, Y '''\n",
        "  # MI(Y; X1)\n",
        "  A = P.sum(axis=1)\n",
        "\n",
        "  # MI(Y; X2)\n",
        "  B = P.sum(axis=0)\n",
        "\n",
        "  # MI(Y; (X1, X2))\n",
        "  C = P.transpose([2, 0, 1]).reshape((P.shape[2], P.shape[0]*P.shape[1]))\n",
        "\n",
        "  return MI(A) + MI(B) - MI(C)\n",
        "\n",
        "def CI(P, Q):\n",
        "  assert P.shape == Q.shape\n",
        "  P_ = P.transpose([2, 0, 1]).reshape((P.shape[2], P.shape[0]*P.shape[1]))\n",
        "  Q_ = Q.transpose([2, 0, 1]).reshape((Q.shape[2], Q.shape[0]*Q.shape[1]))\n",
        "  return MI(P_) - MI(Q_)\n",
        "\n",
        "def UI(P, cond_id=0):\n",
        "  ''' P has 3 dimensions, in order X1, X2, Y \n",
        "  We condition on X1 if cond_id = 0, if 1, then X2.\n",
        "  '''\n",
        "  P_ = np.copy(P)\n",
        "  sum = 0.\n",
        "\n",
        "  if cond_id == 0:\n",
        "    J= P.sum(axis=(1,2)) # marginal of x1\n",
        "    for i in range(P.shape[0]):\n",
        "      sum += MI(P[i,:,:]/P[i,:,:].sum()) * J[i]\n",
        "  elif cond_id == 1:\n",
        "    J= P.sum(axis=(0,2)) # marginal of x1\n",
        "    for i in range(P.shape[1]):\n",
        "      sum += MI(P[:,i,:]/P[:,i,:].sum()) * J[i]\n",
        "  else:\n",
        "    assert False\n",
        "\n",
        "  return sum\n",
        "\n",
        "def test(P):\n",
        "  Q = solve_Q_new(P)\n",
        "  redundancy = CoI(Q)\n",
        "  print('Redundancy', redundancy)\n",
        "  unique_1 = UI(Q, cond_id=1)\n",
        "  print('Unique', unique_1)\n",
        "  unique_2 = UI(Q, cond_id=0)\n",
        "  print('Unique', unique_2)\n",
        "  synergy = CI(P, Q)\n",
        "  print('Synergy', synergy)\n",
        "  return {'redundancy':redundancy, 'unique1':unique_1, 'unique2':unique_2, 'synergy':synergy}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELIMYQ_4aJmw",
        "outputId": "705e5cd3-4082-428f-884c-523be37956cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Redundancy 7.254531412136951e-10\n",
            "Synergy 0.6931471798344919\n",
            "Unique -8.264737925823815e-26\n",
            "Unique -8.264737925823815e-26\n"
          ]
        }
      ],
      "source": [
        "P = np.zeros((2,2,2))\n",
        "P[:,:,0] = np.eye(2) * 0.25\n",
        "P[:,:,1] = np.array([[0., 0.25], [0.25, 0.]])\n",
        "test(P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tglah2m9aIeI",
        "outputId": "138d6db1-f9cd-408e-c596-6a46dfe31cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Redundancy 2.0675621478641933e-07\n",
            "Synergy 0.6931443092606695\n",
            "Unique 2.0027052065158908e-07\n",
            "Unique 7.05164076805474e-11\n"
          ]
        }
      ],
      "source": [
        "data = gen_binary_data(100000)\n",
        "P, maps = convert_data_to_distribution(*data['xor'])\n",
        "test(P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yj1-anihOosP",
        "outputId": "fcb34dff-4f47-45e3-86b4-c9d3cedd5a00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Redundancy 0.21606748068594048\n",
            "Synergy 0.34645409997043997\n",
            "Unique 9.021767949435756e-06\n",
            "Unique 1.0704557540107058e-08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr0/home/yuncheng/miniconda3/envs/multibench/lib/python3.9/site-packages/cvxpy/problems/problem.py:1337: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "data = gen_binary_data(1000000)\n",
        "P, maps = convert_data_to_distribution(*data['and'])\n",
        "test(P)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87NVv_W0i95X",
        "outputId": "57e3e2d6-876c-4a70-ecb0-90a3f3a269bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Redundancy 0.005079711220936332\n",
            "Synergy 0.1224282223359574\n",
            "Unique 0.022288101617060463\n",
            "Unique 0.019486346111584556\n"
          ]
        }
      ],
      "source": [
        "P = np.random.uniform(size=(5,4,3))\n",
        "P = P / np.sum(P)\n",
        "test(P)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### synthetic dataset measures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "I9a60t8jZqk9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Redundancy 0.16721953678967238\n",
            "Unique 0.009443059215327298\n",
            "Unique 0.00038723549898728936\n",
            "Synergy 0.05407597605044967\n"
          ]
        }
      ],
      "source": [
        "with open('synthetic/DATA_redundancy_cluster.pickle', 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "data = (dataset['test']['0'], dataset['test']['1'], dataset['test']['label'])\n",
        "P, maps = convert_data_to_distribution(*data)\n",
        "test(P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Redundancy 0.0024068776832209815\n",
            "Unique 0.17168997263936803\n",
            "Unique -3.9762788372355886e-17\n",
            "Synergy 0.053745916375025876\n"
          ]
        }
      ],
      "source": [
        "with open('synthetic/DATA_uniqueness0_cluster.pickle', 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "data = (dataset['test']['0'], dataset['test']['1'], dataset['test']['label'])\n",
        "P, maps = convert_data_to_distribution(*data)\n",
        "test(P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Redundancy 0.004109998201795223\n",
            "Unique 4.739394431722425e-17\n",
            "Unique 0.16024362610457085\n",
            "Synergy 0.047320072834599824\n"
          ]
        }
      ],
      "source": [
        "with open('synthetic/DATA_uniqueness1_cluster.pickle', 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "data = (dataset['test']['0'], dataset['test']['1'], dataset['test']['label'])\n",
        "P, maps = convert_data_to_distribution(*data)\n",
        "test(P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Redundancy 0.0740888062450043\n",
            "Unique 0.010071939432917378\n",
            "Unique 0.0005577240092090323\n",
            "Synergy 0.1381926821869899\n"
          ]
        }
      ],
      "source": [
        "with open('synthetic/DATA_synergy_cluster.pickle', 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "data = (dataset['test']['0'], dataset['test']['1'], dataset['test']['label'])\n",
        "P, maps = convert_data_to_distribution(*data)\n",
        "test(P)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "redundancy\n",
            "Redundancy 0.16721953678967238\n",
            "Unique 0.009443059215327298\n",
            "Unique 0.00038723549898728936\n",
            "Synergy 0.05407597605044967\n",
            "uniqueness0\n",
            "Redundancy 0.0024068776832209815\n",
            "Unique 0.17168997263936803\n",
            "Unique -3.9762788372355886e-17\n",
            "Synergy 0.053745916375025876\n",
            "uniqueness1\n",
            "Redundancy 0.004109998201795223\n",
            "Unique 4.739394431722425e-17\n",
            "Unique 0.16024362610457085\n",
            "Synergy 0.047320072834599824\n",
            "synergy\n",
            "Redundancy 0.0740888062450043\n",
            "Unique 0.010071939432917378\n",
            "Unique 0.0005577240092090323\n",
            "Synergy 0.1381926821869899\n",
            "mix1\n",
            "Redundancy 0.05076955525118054\n",
            "Unique 0.005163602945388254\n",
            "Unique 0.0012951574877414992\n",
            "Synergy 0.07132778066395776\n",
            "mix2\n",
            "Redundancy 0.05399747675209331\n",
            "Unique 0.05768927022274116\n",
            "Unique 7.126959113402868e-16\n",
            "Synergy 0.07139916901767802\n",
            "mix3\n",
            "Redundancy 0.07978805424537334\n",
            "Unique 0.008983824324279941\n",
            "Unique 0.0013647931713488403\n",
            "Synergy 0.11584163577704519\n",
            "mix4\n",
            "Redundancy 0.09086883240778226\n",
            "Unique 0.0027345520262268383\n",
            "Unique 0.0056027411357744425\n",
            "Synergy 0.07627241778313054\n",
            "mix5\n",
            "Redundancy 0.040488846567257125\n",
            "Unique 2.7507095153340126e-15\n",
            "Unique 0.037628033178334214\n",
            "Synergy 0.058356058297650115\n",
            "mix6\n",
            "Redundancy 0.11626931769341098\n",
            "Unique 0.00011536496283437236\n",
            "Unique 0.029379107437630458\n",
            "Synergy 0.05438394698308682\n"
          ]
        }
      ],
      "source": [
        "results = dict()\n",
        "for setting in ['redundancy', 'uniqueness0', 'uniqueness1', 'synergy', 'mix1', 'mix2', 'mix3', 'mix4', 'mix5', 'mix6']:\n",
        "    with open('synthetic/DATA_{}_cluster.pickle'.format(setting), 'rb') as f:\n",
        "        dataset = pickle.load(f)\n",
        "    print(setting)\n",
        "    data = (dataset['test']['0'], dataset['test']['1'], dataset['test']['label'])\n",
        "    P, maps = convert_data_to_distribution(*data)\n",
        "    result = test(P)\n",
        "    results[setting] = result\n",
        "\n",
        "with open('synthetic/experiments/datasets.pickle', 'wb') as f:\n",
        "    pickle.dump(results, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "multibench",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "8158f520b0615a91d72976457965394544e0f25ca15232774db0f5a21042574b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
